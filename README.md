# Accuracy of a Vision-Language Model on Challenging Medical Cases
Thomas Buckley, James A. Diao, B.S., Adam Rodman, M.D., and Arjun K. Manrai, Ph.D.

**Abstract** 

Background: General-purpose large language models that utilize both text and images have not been evaluated on a diverse array of challenging medical cases.
 
Methods: Using 934 cases from the NEJM Image Challenge published between 2005 and 2023, we evaluated the accuracy of the recently released Generative Pre-trained Transformer 4 model (GPT-4V) compared to human respondents overall and stratified by question difficulty, level of disagreement, image type, and skin tone. We further conducted a physician evaluation of GPT-4V on 70 NEJM Clinicopathological Conferences (CPCs). Analyses were conducted for models utilizing text alone, images alone, and both text and images.
 
Results: GPT-4V achieved an overall accuracy of 61% (95% CI, 58% to 64%) compared to 49% (95% CI, 49% to 50%) for humans. GPT-4V outperformed humans at all levels of difficulty and disagreement, skin tones, and image types; the one exception was radiographic images, where performance was equivalent between GPT-4V and human respondents. Longer and more informative captions were associated with improved performance for GPT-4V but similar performance for human respondents. GPT-4V included the correct diagnosis in its differential for 80% of CPCs when using text alone, compared to 58% of CPCs when using both images and text.

Conclusions: GPT-4V outperformed human respondents on challenging medical cases and was able to synthesize information from both images and text, but performance deteriorated when images were added to highly informative text. Overall, our results suggest that multimodal AI models may be useful in medical diagnostic reasoning but that their accuracy may depend heavily on context.
